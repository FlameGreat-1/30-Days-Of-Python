{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mastering Pandas for Data Manipulation and Analysis\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Pandas is a powerful library for data manipulation and analysis in Python. It provides high-performance, easy-to-use data structures and data analysis tools. In this lecture, we'll dive deep into Pandas, covering everything from basic concepts to advanced techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pandas Fundamentals\n",
    "\n",
    "### 1.1 Series and DataFrame objects\n",
    "\n",
    "The two primary data structures in Pandas are Series and DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Series\n",
    "s = pd.Series([1, 3, 5, np.nan, 6, 8])\n",
    "print(\"Series:\")\n",
    "print(s)\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4],\n",
    "    'B': pd.Timestamp('20230101'),\n",
    "    'C': pd.Series(1, index=list(range(4)), dtype='float32'),\n",
    "    'D': np.array([3] * 4, dtype='int32'),\n",
    "    'E': pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
    "    'F': 'foo'\n",
    "})\n",
    "print(\"\\nDataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Creating, reading, and writing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame from a dictionary\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['John', 'Anna', 'Peter', 'Linda'],\n",
    "    'Age': [28, 34, 29, 32],\n",
    "    'City': ['New York', 'Paris', 'Berlin', 'London']\n",
    "})\n",
    "\n",
    "# Writing to CSV\n",
    "df.to_csv('people.csv', index=False)\n",
    "\n",
    "# Reading from CSV\n",
    "df_csv = pd.read_csv('people.csv')\n",
    "print(\"DataFrame from CSV:\")\n",
    "print(df_csv)\n",
    "\n",
    "# Writing to Excel\n",
    "df.to_excel('people.xlsx', index=False)\n",
    "\n",
    "# Reading from Excel\n",
    "df_excel = pd.read_excel('people.xlsx')\n",
    "print(\"\\nDataFrame from Excel:\")\n",
    "print(df_excel)\n",
    "\n",
    "# Note: For SQL databases, you would typically use pd.read_sql() and df.to_sql()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Understanding and manipulating index objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame with a custom index\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4],\n",
    "    'B': ['a', 'b', 'c', 'd']\n",
    "}, index=['w', 'x', 'y', 'z'])\n",
    "print(\"DataFrame with custom index:\")\n",
    "print(df)\n",
    "\n",
    "# Accessing the index\n",
    "print(\"\\nIndex:\")\n",
    "print(df.index)\n",
    "\n",
    "# Setting a new index\n",
    "df.set_index('B', inplace=True)\n",
    "print(\"\\nDataFrame with 'B' as index:\")\n",
    "print(df)\n",
    "\n",
    "# Resetting the index\n",
    "df.reset_index(inplace=True)\n",
    "print(\"\\nDataFrame with reset index:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Preprocessing\n",
    "\n",
    "### 2.1 Handling missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with missing values\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4],\n",
    "    'B': [5, np.nan, np.nan, 8],\n",
    "    'C': [9, 10, 11, 12]\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Filling NA values\n",
    "print(\"\\nFilling NA with 0:\")\n",
    "print(df.fillna(0))\n",
    "\n",
    "# Dropping NA values\n",
    "print(\"\\nDropping rows with NA:\")\n",
    "print(df.dropna())\n",
    "\n",
    "# Interpolating values\n",
    "print(\"\\nInterpolating NA values:\")\n",
    "print(df.interpolate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Removing duplicates and handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with duplicates and outliers\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 2, 3, 1000],  # 1000 is an outlier\n",
    "    'B': ['a', 'b', 'b', 'c', 'd']\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Remove duplicates\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "print(\"\\nDataFrame without duplicates:\")\n",
    "print(df_no_duplicates)\n",
    "\n",
    "# Handle outliers (here, we'll remove rows where 'A' is more than 3 standard deviations from the mean)\n",
    "mean = df['A'].mean()\n",
    "std = df['A'].std()\n",
    "df_no_outliers = df[(df['A'] - mean).abs() <= 3 * std]\n",
    "print(\"\\nDataFrame without outliers:\")\n",
    "print(df_no_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data type conversion and category encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': ['1', '2', '3', '4'],\n",
    "    'B': ['low', 'medium', 'high', 'low'],\n",
    "    'C': ['2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04']\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Convert 'A' to integer\n",
    "df['A'] = df['A'].astype(int)\n",
    "\n",
    "# Convert 'B' to category\n",
    "df['B'] = df['B'].astype('category')\n",
    "\n",
    "# Convert 'C' to datetime\n",
    "df['C'] = pd.to_datetime(df['C'])\n",
    "\n",
    "print(\"\\nDataFrame after type conversion:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Encode 'B' as numeric\n",
    "df['B_encoded'] = df['B'].cat.codes\n",
    "print(\"\\nDataFrame with encoded 'B':\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 String manipulation with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with string data\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['John Smith', 'Jane Doe', 'Mike Johnson'],\n",
    "    'Email': ['john@example.com', 'jane@example.com', 'mike@example.com']\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Extract first name\n",
    "df['First Name'] = df['Name'].str.split().str[0]\n",
    "\n",
    "# Extract domain from email\n",
    "df['Domain'] = df['Email'].str.split('@').str[1]\n",
    "\n",
    "# Convert name to uppercase\n",
    "df['Name Upper'] = df['Name'].str.upper()\n",
    "\n",
    "print(\"\\nDataFrame after string operations:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced Data Transformation\n",
    "\n",
    "### 3.1 Reshaping data: pivot, melt, stack, and unstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Date': ['2021-01-01', '2021-01-01', '2021-01-02', '2021-01-02'],\n",
    "    'Product': ['A', 'B', 'A', 'B'],\n",
    "    'Sales': [100, 150, 120, 180]\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Pivot\n",
    "df_pivot = df.pivot(index='Date', columns='Product', values='Sales')\n",
    "print(\"\\nPivoted DataFrame:\")\n",
    "print(df_pivot)\n",
    "\n",
    "# Melt\n",
    "df_melt = pd.melt(df_pivot.reset_index(), id_vars=['Date'], var_name='Product', value_name='Sales')\n",
    "print(\"\\nMelted DataFrame:\")\n",
    "print(df_melt)\n",
    "\n",
    "# Stack\n",
    "df_stack = df_pivot.stack()\n",
    "print(\"\\nStacked DataFrame:\")\n",
    "print(df_stack)\n",
    "\n",
    "# Unstack\n",
    "df_unstack = df_stack.unstack()\n",
    "print(\"\\nUnstacked DataFrame:\")\n",
    "print(df_unstack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Grouping and aggregation with groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Category': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
    "    'Value1': [10, 20, 30, 40, 50, 60],\n",
    "    'Value2': [100, 200, 300, 400, 500, 600]\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Group by Category and calculate mean\n",
    "grouped_mean = df.groupby('Category').mean()\n",
    "print(\"\\nGrouped Mean:\")\n",
    "print(grouped_mean)\n",
    "\n",
    "# Group by Category and apply multiple aggregations\n",
    "grouped_agg = df.groupby('Category').agg({\n",
    "    'Value1': ['mean', 'sum'],\n",
    "    'Value2': ['min', 'max']\n",
    "})\n",
    "print(\"\\nGrouped with multiple aggregations:\")\n",
    "print(grouped_agg)\n",
    "\n",
    "# Custom aggregation function\n",
    "def range_func(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "grouped_custom = df.groupby('Category').agg({\n",
    "    'Value1': range_func,\n",
    "    'Value2': range_func\n",
    "})\n",
    "print(\"\\nGrouped with custom aggregation:\")\n",
    "print(grouped_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Applying functions with apply, applymap, and map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [10, 20, 30],\n",
    "    'C': ['a', 'b', 'c']\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Using apply on a single column\n",
    "df['A_squared'] = df['A'].apply(lambda x: x**2)\n",
    "print(\"\\nAfter applying square function to column A:\")\n",
    "print(df)\n",
    "\n",
    "# Using apply on the entire DataFrame\n",
    "df_applied = df.apply(lambda x: x.max() if x.dtype == 'int64' else x, axis=0)\n",
    "print(\"\\nAfter applying max function to numeric columns:\")\n",
    "print(df_applied)\n",
    "\n",
    "# Using applymap on the entire DataFrame\n",
    "df_applymap = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
    "print(\"\\nAfter applying uppercase to string values:\")\n",
    "print(df_applymap)\n",
    "\n",
    "# Using map on a single column\n",
    "mapping = {'a': 'Apple', 'b': 'Banana', 'c': 'Cherry'}\n",
    "df['C_mapped'] = df['C'].map(mapping)\n",
    "print(\"\\nAfter mapping values in column C:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Merging, joining, and concatenating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrames\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2'], 'B': ['B0', 'B1', 'B2']}, index=['K0', 'K1', 'K2'])\n",
    "df2 = pd.DataFrame({'C': ['C0', 'C1', 'C2'], 'D': ['D0', 'D1', 'D2']}, index=['K0', 'K2', 'K3'])\n",
    "df3 = pd.DataFrame({'A': ['A0', 'A1', 'A2'], 'B': ['B0', 'B1', 'B2']}, index=['K0', 'K1', 'K2'])\n",
    "\n",
    "print(\"DataFrame 1:\")\n",
    "print(df1)\n",
    "print(\"\\nDataFrame 2:\")\n",
    "print(df2)\n",
    "print(\"\\nDataFrame 3:\")\n",
    "print(df3)\n",
    "\n",
    "# Merging DataFrames\n",
    "merged = pd.merge(df1, df2, left_index=True, right_index=True, how='outer')\n",
    "print(\"\\nMerged DataFrame:\")\n",
    "print(merged)\n",
    "\n",
    "# Joining DataFrames\n",
    "joined = df1.join(df2, how='outer')\n",
    "print(\"\\nJoined DataFrame:\")\n",
    "print(joined)\n",
    "\n",
    "# Concatenating DataFrames\n",
    "concatenated = pd.concat([df1, df3])\n",
    "print(concatenated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Indexing and Selection\n",
    "\n",
    "### 4.1 Boolean indexing and masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [10, 20, 30, 40, 50],\n",
    "    'C': ['a', 'b', 'c', 'd', 'e']\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Boolean indexing\n",
    "mask = df['A'] > 2\n",
    "print(\"\\nRows where A > 2:\")\n",
    "print(df[mask])\n",
    "\n",
    "# Multiple conditions\n",
    "mask = (df['A'] > 2) & (df['B'] < 50)\n",
    "print(\"\\nRows where A > 2 and B < 50:\")\n",
    "print(df[mask])\n",
    "\n",
    "# Boolean indexing with isin\n",
    "mask = df['C'].isin(['a', 'c', 'e'])\n",
    "print(\"\\nRows where C is 'a', 'c', or 'e':\")\n",
    "print(df[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Hierarchical indexing (MultiIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with MultiIndex\n",
    "arrays = [\n",
    "    ['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],\n",
    "    ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']\n",
    "]\n",
    "df = pd.DataFrame(np.random.randn(8, 4), index=arrays)\n",
    "df.index.names = ['first', 'second']\n",
    "print(\"DataFrame with MultiIndex:\")\n",
    "print(df)\n",
    "\n",
    "# Selecting using MultiIndex\n",
    "print(\"\\nSelecting 'bar' from first level:\")\n",
    "print(df.loc['bar'])\n",
    "\n",
    "print(\"\\nSelecting 'bar' and 'one' from first and second levels:\")\n",
    "print(df.loc[('bar', 'one')])\n",
    "\n",
    "# Cross-section selection\n",
    "print(\"\\nCross-section selection for second level 'one':\")\n",
    "print(df.xs('one', level='second'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Advanced loc and iloc usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [10, 20, 30, 40, 50],\n",
    "    'C': ['a', 'b', 'c', 'd', 'e']\n",
    "}, index=['row1', 'row2', 'row3', 'row4', 'row5'])\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Using loc\n",
    "print(\"\\nSelecting rows 'row2' to 'row4' and columns 'A' and 'C' using loc:\")\n",
    "print(df.loc['row2':'row4', ['A', 'C']])\n",
    "\n",
    "# Using iloc\n",
    "print(\"\\nSelecting rows 1 to 3 and columns 0 and 2 using iloc:\")\n",
    "print(df.iloc[1:4, [0, 2]])\n",
    "\n",
    "# Mixing loc and iloc\n",
    "print(\"\\nMixing loc and iloc:\")\n",
    "print(df.iloc[1:4].loc[:, ['A', 'C']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Time Series Analysis\n",
    "\n",
    "### 5.1 Working with datetime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with datetime index\n",
    "dates = pd.date_range('20210101', periods=6)\n",
    "df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list('ABCD'))\n",
    "print(\"DataFrame with datetime index:\")\n",
    "print(df)\n",
    "\n",
    "# Selecting specific dates\n",
    "print(\"\\nSelecting a specific date:\")\n",
    "print(df.loc['2021-01-03'])\n",
    "\n",
    "# Selecting date ranges\n",
    "print(\"\\nSelecting a date range:\")\n",
    "print(df['2021-01-02':'2021-01-04'])\n",
    "\n",
    "# Date arithmetic\n",
    "print(\"\\nAdding 2 days to the index:\")\n",
    "print(df.index + pd.Timedelta(days=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Resampling and rolling window calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series DataFrame\n",
    "dates = pd.date_range('20210101', periods=100, freq='D')\n",
    "ts = pd.Series(np.random.randn(len(dates)), index=dates)\n",
    "print(\"Original time series:\")\n",
    "print(ts.head())\n",
    "\n",
    "# Resampling to monthly frequency\n",
    "monthly = ts.resample('M').mean()\n",
    "print(\"\\nMonthly resampled data:\")\n",
    "print(monthly)\n",
    "\n",
    "# Rolling window calculations\n",
    "rolling = ts.rolling(window=7).mean()\n",
    "print(\"\\n7-day rolling average:\")\n",
    "print(rolling.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Handling time zones and periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series with time zone\n",
    "rng = pd.date_range('3/6/2012 00:00', periods=5, freq='D', tz='US/Eastern')\n",
    "ts = pd.Series(np.random.randn(len(rng)), rng)\n",
    "print(\"Time series with time zone:\")\n",
    "print(ts)\n",
    "\n",
    "# Convert to another time zone\n",
    "print(\"\\nConverted to UTC:\")\n",
    "print(ts.tz_convert('UTC'))\n",
    "\n",
    "# Create a period index\n",
    "prng = pd.period_range('1990Q1', '2000Q4', freq='Q-NOV')\n",
    "ts = pd.Series(np.random.randn(len(prng)), prng)\n",
    "print(\"\\nTime series with period index:\")\n",
    "print(ts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Optimization\n",
    "\n",
    "### 6.1 Using categorical data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with categorical data\n",
    "df = pd.DataFrame({\n",
    "    'id': range(1000000),\n",
    "    'value': np.random.randint(0, 100, size=1000000),\n",
    "    'category': np.random.choice(['A', 'B', 'C', 'D'], size=1000000)\n",
    "})\n",
    "\n",
    "print(\"Memory usage before optimization:\")\n",
    "print(df.memory_usage(deep=True))\n",
    "\n",
    "# Convert 'category' column to categorical type\n",
    "df['category'] = df['category'].astype('category')\n",
    "\n",
    "print(\"\\nMemory usage after optimization:\")\n",
    "print(df.memory_usage(deep=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Efficient iteration with itertuples and iterrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': range(10000),\n",
    "    'B': range(10000, 20000),\n",
    "    'C': range(20000, 30000)\n",
    "})\n",
    "\n",
    "# Using iterrows\n",
    "start = time.time()\n",
    "for index, row in df.iterrows():\n",
    "    _ = row['A'] + row['B'] + row['C']\n",
    "print(f\"Time taken with iterrows: {time.time() - start:.4f} seconds\")\n",
    "\n",
    "# Using itertuples\n",
    "start = time.time()\n",
    "for row in df.itertuples(index=False):\n",
    "    _ = row.A + row.B + row.C\n",
    "print(f\"Time taken with itertuples: {time.time() - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Vectorization techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': np.random.randn(1000000),\n",
    "    'B': np.random.randn(1000000)\n",
    "})\n",
    "\n",
    "# Non-vectorized operation\n",
    "start = time.time()\n",
    "result = []\n",
    "for i in range(len(df)):\n",
    "    result.append(df.iloc[i]['A'] + df.iloc[i]['B'])\n",
    "print(f\"Time taken with loop: {time.time() - start:.4f} seconds\")\n",
    "\n",
    "# Vectorized operation\n",
    "start = time.time()\n",
    "result = df['A'] + df['B']\n",
    "print(f\"Time taken with vectorization: {time.time() - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Using numba with Pandas for performance boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "\n",
    "@jit(nopython=True)\n",
    "def add_columns_numba(A, B):\n",
    "    return A + B\n",
    "\n",
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': np.random.randn(1000000),\n",
    "    'B': np.random.randn(1000000)\n",
    "})\n",
    "\n",
    "# Pandas operation\n",
    "start = time.time()\n",
    "result_pandas = df['A'] + df['B']\n",
    "print(f\"Time taken with Pandas: {time.time() - start:.4f} seconds\")\n",
    "\n",
    "# Numba operation\n",
    "start = time.time()\n",
    "result_numba = add_columns_numba(df['A'].values, df['B'].values)\n",
    "print(f\"Time taken with Numba: {time.time() - start:.4f} seconds\")\n",
    "\n",
    "# Verify results are the same\n",
    "print(f\"Results are equal: {np.allclose(result_pandas, result_numba)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This comprehensive lecture has covered advanced topics in Pandas, including data manipulation, analysis, and performance optimization. By mastering these concepts, you'll be well-equipped to handle complex data tasks efficiently using Pandas.\n",
    "\n",
    "Remember to practice these techniques with real-world datasets to solidify your understanding and improve your skills in data analysis with Python and Pandas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
